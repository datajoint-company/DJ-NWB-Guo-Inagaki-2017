{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guo-Inagaki-2017 - A DataJoint example\n",
    "\n",
    "The data and results presented in this notebook pertain to the paper:\n",
    ">Zengcai V. Guo, Hidehiko K. Inagaki, Kayvon Daie, Shaul Druckmann, Charles R. Gerfen & Karel Svoboda. \"Maintenance of persistent activity in a frontal thalamocortical loop\" (2017) Nature\n",
    "(https://dx.doi.org/10.1038/nature22324)\n",
    "\n",
    "\n",
    "This notebook provide demonstrations of working with a DataJoint data pipeline in querying data, apply data conditioning and reproduce some key figures in the paper. The orignal data , in *NWB 2.0* format, had been ingested into a DataJoint data pipeline (data pipeline schema is given below). As a validation of complete ingestion of the original data into DataJoint, figures 3b,e, 6b,e and 4b,e,h will be reproduced in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from pipeline import reference, subject, acquisition, stimulation, analysis #, behavior, ephys, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "all_erd = dj.ERD(reference) + dj.ERD(subject) + dj.ERD(acquisition) + dj.ERD(stimulation) + dj.ERD(analysis)\n",
    "dj.ERD(all_erd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce Figure 4b, e, f\n",
    "First, we wish to demonstrate the queries and reproduction of figures 4b, 4e and 4h in the paper. These figures represents population-level membrane potentials of intracellular recordings, in response to photostimulation, of the entire study. To investigate the responses to photostimulation, we wish to visualize the membrane potentials responses time-locked to the onset of the \"delay\" period, where photostimulation was performed. This trial-based segmentation has already been performed and results stored in DataJoint, however appropriate queries are still required.  \n",
    "\n",
    "Specifically, we need to first query membrane potentials recordings from all sessions and categorize based on: \n",
    "+ Photostim location: contralateral ALM, Thalamus, and M1\n",
    "+ Trial condition: good trials without stimulation (control) and with stimulation (stim)\n",
    "\n",
    "In this data pipeline, a recording session contains the acquired intracellular recordings, and the photostimulation, which specifies brain location the stimulation was performed on. We need to use this photostimulation information to constrain the queries of trial-segmented membrane potentials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Get all whole cell\n",
    "cell_keys = acquisition.Cell.fetch(dj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Backtrack session, and get photostim info\n",
    "# photostim keys for contra ALM stimulation\n",
    "region_dict = {'brain_region':'ALM', 'hemisphere':'right'}\n",
    "contraALM_photostims = (acquisition.PhotoStimulation & cell_keys & region_dict).fetch('KEY')\n",
    "# photostim keys for thalamus stimulation\n",
    "region_dict = {'brain_region':'VM', 'hemisphere':'left'}\n",
    "thal_photostims = (acquisition.PhotoStimulation & cell_keys & region_dict).fetch('KEY')\n",
    "# photostim keys for M1 stimulation\n",
    "region_dict = {'brain_region':'M1', 'hemisphere':'left'}\n",
    "m1_photostims = (acquisition.PhotoStimulation & cell_keys & region_dict).fetch('KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- define cell restrictor for each stim location\n",
    "contraALM_stim_cells = (acquisition.Cell & contraALM_photostims).fetch('KEY')\n",
    "thal_stim_cells = (acquisition.Cell & thal_photostims).fetch('KEY')\n",
    "m1_stim_cells = (acquisition.Cell & m1_photostims).fetch('KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, whole-cell recordings sessions (session-key) with photostimulation at contralateral ALM, Thalamus, and M1 are embedded in the variables *contraALM_stim_cells*, *thal_stim_cells* and *m1_stim_cells* respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some trial restrictor \n",
    "stim_trial_cond = {'trial_is_good': True, 'trial_stim_present': True}\n",
    "ctrl_trial_cond = {'trial_is_good': True, 'trial_stim_present': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define trial-segmentation setting \n",
    "seg_param_key = (analysis.TrialSegmentationSetting & {'event': 'pole_out', 'pre_stim_duration': 1.5, 'post_stim_duration': 3}).fetch1('KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, for convenient operations we define a function to query trial-segmented intracellular recordings based on the session-key, and trial-restrictor defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_segmented_intracellular(cell_key, trial_key, seg_param_key):\n",
    "    data_keys = (analysis.TrialSegmentedIntracellular & cell_key & seg_param_key &\n",
    "                 (acquisition.TrialSet.Trial & trial_key))\n",
    "    return [{**dict(zip(['segmented_mp', 'segmented_mp_wo_spike'],\n",
    "                        (analysis.TrialSegmentedIntracellular.MembranePotential & k).fetch1(\n",
    "                            'segmented_mp', 'segmented_mp_wo_spike'))),\n",
    "             **dict(zip(*(analysis.RealignedEvent.RealignedEventTime & k).fetch(\n",
    "                 'realigned_trial_event', 'realigned_event_time')))}\n",
    "            for k in data_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query trial-segmented data based on the cell and trial restrictors    \n",
    "trial_segmented_ic = {ic_loc: {'stim': query_segmented_intracellular(ic_loc_key, stim_trial_cond, seg_param_key),\n",
    "                                'ctrl': query_segmented_intracellular(ic_loc_key, ctrl_trial_cond, seg_param_key)}\n",
    "                      for ic_loc, ic_loc_key in zip(('thalamus', 'm1', 'contraALM'), (thal_stim_cells, m1_stim_cells, contraALM_stim_cells))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sampling rate\n",
    "fs = acquisition.IntracellularAcquisition.MembranePotential.fetch('membrane_potential_sampling_rate', limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "avg_trial_segmented_ic = {ic_key: {'stim':{\n",
    "                                       'data': np.vstack([k['segmented_mp_wo_spike'][:min(k['segmented_mp_wo_spike'].size\n",
    "                                                                                          for k in trial_segmented_ic[ic_key]['stim'])] \n",
    "                                                          for k in trial_segmented_ic[ic_key]['stim']]),\n",
    "                                       'timestamps': np.arange(min(k['segmented_mp_wo_spike'].size \n",
    "                                                                   for k in trial_segmented_ic[ic_key]['stim'])) / fs - float(seg_param_key['pre_stim_duration'])},\n",
    "                                    'ctrl':{\n",
    "                                       'data': np.vstack([k['segmented_mp_wo_spike'][:min(k['segmented_mp_wo_spike'].size\n",
    "                                                                                          for k in trial_segmented_ic[ic_key]['ctrl'])] \n",
    "                                                          for k in trial_segmented_ic[ic_key]['ctrl']]),\n",
    "                                       'timestamps': np.arange(min(k['segmented_mp_wo_spike'].size \n",
    "                                                                   for k in trial_segmented_ic[ic_key]['ctrl'])) / fs - float(seg_param_key['pre_stim_duration'])}\n",
    "                                   } for ic_key in trial_segmented_ic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_sem(data1, data2, ax):\n",
    "    for d, c, s in zip((data1, data2), ('b', 'k'), ('b', 'gray')):\n",
    "        v_mean = d['data'].mean(axis=0)\n",
    "        v_sem = d['data'].std(axis=0) / np.sqrt(data1['data'].shape[0])\n",
    "        ax.plot(d['timestamps'], v_mean, c)\n",
    "        ax.fill_between(d['timestamps'], v_mean - v_sem, v_mean + v_sem, alpha=0.5, facecolor=s)          \n",
    "    ax.axvline(x=0, linestyle='--', color='k')\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig4, axs = plt.subplots(len(avg_trial_segmented_ic), 1, figsize=(6, 6))\n",
    "fig4.subplots_adjust(hspace=0.4)\n",
    "\n",
    "for avg, ax in zip(avg_trial_segmented_ic.values(), axs):\n",
    "    plot_with_sem(avg['stim'], avg['ctrl'], ax)\n",
    "    ax.set_xlim(-0.1, 1.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce Figure 3b, 6b - Extracellular\n",
    "The following parts of this example relates to the extracellular recording results of this study, namedly the neuronal spiking patterns in response to photostimulation \n",
    "\n",
    "Fairly similar to the routine layed out above, we wish to query neuronal spike times, segmented time-locked to the \"delay\" period, categorized by recording locations and photostimulation locations:\n",
    "+ Record at ALM, stimulation at ALM\n",
    "+ Record at ALM, stimulation at Thalamus\n",
    "+ Record at Thalamus, stimulation at Thalamus\n",
    "+ Record at Thalamus, stimulation at ALM\n",
    "\n",
    "Also with two trial-based conditions: good trials without stimulation (control) and with stimulation (stim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get trial-segmented spiketimes for a single unit in the one specifed session\n",
    "def query_unit_segmented_spiketimes(sess_key, unit, trial_key, seg_param_key):\n",
    "    data_keys = (analysis.TrialSegmentedUnitSpikeTimes & sess_key & {'unit_id': unit} & seg_param_key &\n",
    "                 (acquisition.TrialSet.Trial & trial_key)).fetch(dj.key)\n",
    "    return pd.DataFrame([dict(**dict(zip(*(analysis.RealignedEvent.RealignedEventTime & k).fetch('realigned_trial_event', 'realigned_event_time'))), \n",
    "                 segmented_spike_times=(analysis.TrialSegmentedUnitSpikeTimes & k).fetch1(\n",
    "                     'segmented_spike_times')) for k in data_keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spike_raster_and_histogram(contra_spike_times, ipsi_spike_times, axes, ax_title='', bin_counts=200):\n",
    "    # get event timing\n",
    "    events = ['pole_in', 'pole_out', 'cue_start']\n",
    "    event_times = np.around([np.hstack([ipsi_spike_times[e], contra_spike_times[e]]).mean() for e in events], 4)\n",
    "    \n",
    "    # restructure data for spike raster  \n",
    "    ipsi_c_trial_idx, ipsi_c_spike_times = zip(*((np.full_like(r, ri), r)\n",
    "                                            for ri, r in enumerate(r for r in ipsi_spike_times.segmented_spike_times if len(r) != 0)))\n",
    "    ipsi_c_trial_idx = np.hstack(ipsi_c_trial_idx)\n",
    "    ipsi_c_spike_times = np.hstack(ipsi_c_spike_times)    \n",
    "    \n",
    "    contra_c_trial_idx, contra_c_spike_times = zip(*((np.full_like(r, ri), r)\n",
    "                                            for ri, r in enumerate(r for r in contra_spike_times.segmented_spike_times if len(r) != 0)))\n",
    "    contra_c_trial_idx = np.hstack(contra_c_trial_idx)\n",
    "    contra_c_spike_times = np.hstack(contra_c_spike_times)  \n",
    "    \n",
    "    # spiketime histogram\n",
    "    time_range = (np.hstack([ipsi_spike_times.trial_start, contra_spike_times.trial_start]).min(),\n",
    "                  np.hstack([ipsi_spike_times.trial_stop, contra_spike_times.trial_stop]).max())\n",
    "\n",
    "    ipsi_spk_counts, ipsi_edges = np.histogram(np.hstack([r for r in ipsi_spike_times.segmented_spike_times]),\n",
    "                                       bins=bin_counts,\n",
    "                                       range=(time_range[0], time_range[-1]))\n",
    "    ipsi_spk_rates = ipsi_spk_counts / np.diff(ipsi_edges) / ipsi_spike_times.segmented_spike_times.shape[0]\n",
    "    \n",
    "    contra_spk_counts, contra_edges = np.histogram(np.hstack([r for r in contra_spike_times.segmented_spike_times]),\n",
    "                                       bins=bin_counts,\n",
    "                                       range=(time_range[0], time_range[-1]))\n",
    "    contra_spk_rates = contra_spk_counts / np.diff(contra_edges) / contra_spike_times.segmented_spike_times.shape[0]\n",
    "   \n",
    "    # plot\n",
    "    # spike raster\n",
    "    ax_top = axes[0]\n",
    "    ax_top.plot(contra_c_spike_times, contra_c_trial_idx + ipsi_c_trial_idx.max(), '|r')\n",
    "    ax_top.plot(ipsi_c_spike_times, ipsi_c_trial_idx, '|b')\n",
    "    # event markers\n",
    "    for e in event_times:\n",
    "        ax_top.axvline(x=e, linestyle='--', color='k')\n",
    "    ax_top.set_xticklabels([])\n",
    "    ax_top.set_yticklabels([])\n",
    "    ax_top.set_ylabel(ax_title)\n",
    "    ax_top.set_xlim(-1.5, 3);\n",
    "    \n",
    "    # spike histogram\n",
    "    ax_bot = axes[1]\n",
    "    ax_bot.plot(ipsi_edges[1:], ipsi_spk_rates, 'b')\n",
    "    ax_bot.plot(contra_edges[1:], contra_spk_rates, 'r')\n",
    "    for e in event_times:\n",
    "        ax_bot.axvline(x=e, linestyle='--', color='k')\n",
    "    ax_bot.set_xlim(-1.5, 3);\n",
    "    \n",
    "    # Hide the spines\n",
    "    ax_top.spines['right'].set_visible(False)\n",
    "    ax_top.spines['top'].set_visible(False)\n",
    "    ax_top.spines['left'].set_visible(False)\n",
    "    ax_top.spines['bottom'].set_visible(False)\n",
    "    ax_bot.spines['right'].set_visible(False)\n",
    "    ax_bot.spines['top'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blue - correct contra trial (licking-right) ; red - correct ipsi trial (licking left)\n",
    "correct_contra_trial_stim =  {'trial_is_good': True, 'trial_stim_present': True, 'trial_type': 'lick right'}\n",
    "correct_ipsi_trial_stim =  {'trial_is_good': True, 'trial_stim_present': True, 'trial_type': 'lick left'}\n",
    "correct_contra_trial_ctrl =  {'trial_is_good': True, 'trial_stim_present': False, 'trial_type': 'lick right'}\n",
    "correct_ipsi_trial_ctrl =  {'trial_is_good': True, 'trial_stim_present': False, 'trial_type': 'lick left'}\n",
    "\n",
    "ec_alm_insert = (acquisition.ProbeInsertion & {'brain_region': 'ALM', 'hemisphere': 'left'})\n",
    "ec_thal_insert = (acquisition.ProbeInsertion & {'brain_region': 'thalamus', 'hemisphere': 'left'})\n",
    "\n",
    "alm_photostim = (acquisition.PhotoStimulation & {'brain_region': 'ALM', 'hemisphere': 'left'})\n",
    "thal_photostim = (acquisition.PhotoStimulation & {'brain_region': 'thalamus', 'hemisphere': 'left'})\n",
    "\n",
    "# ALM probe with ALM or Thalamus photostim\n",
    "alm_insert_alm_stim = (acquisition.Session & ec_alm_insert) & (acquisition.Session & alm_photostim).fetch('KEY')\n",
    "alm_insert_thal_stim = (acquisition.Session & ec_alm_insert) & (acquisition.Session & thal_photostim).fetch('KEY')\n",
    "# Thalamus probe with ALM or Thalamus photostim\n",
    "thal_insert_alm_stim = (acquisition.Session & ec_thal_insert) & (acquisition.Session & alm_photostim).fetch('KEY')\n",
    "thal_insert_thal_stim = (acquisition.Session & ec_thal_insert) & (acquisition.Session & thal_photostim).fetch('KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example unit - Fig 3b & 6b\n",
    "We pick some arbitrary neuronal units for plotting the spike raster and spike histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Chery-picking unit and session...\n",
    "# for idx, sess in enumerate(alm_insert_thal_stim.fetch('KEY')): # pick one session here\n",
    "#     print([idx, len(acquisition.TrialSet.Trial & sess & correct_contra_trial_stim),\n",
    "#            len(acquisition.TrialSet.Trial & sess & correct_ipsi_trial_stim)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get segmented spike times for one unit - ALM-insert, thal-stim\n",
    "def make_unit_spiketimes(unit, sess):\n",
    "    return {k: query_unit_segmented_spiketimes(sess, unit, v, seg_param_key) \n",
    "            for k, v in zip(('contra_ctrl', 'ipsi_ctrl', 'contra_stim', 'ipsi_stim'), \n",
    "                            (correct_contra_trial_ctrl, correct_ipsi_trial_ctrl, \n",
    "                             correct_contra_trial_stim, correct_ipsi_trial_stim))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 units with ALM insert and Thalamus photostim\n",
    "sess = alm_insert_thal_stim.fetch('KEY')\n",
    "alm_insert_thal_stim_unit = [ make_unit_spiketimes(unit=unit_no, sess=sess[session_no]) \n",
    "                             for unit_no, session_no in zip((1, 1, 1), (21, 34, 19))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spike raster and histogram\n",
    "bin_counts = 200\n",
    "fig3, axs = plt.subplots(4, len(alm_insert_thal_stim_unit), figsize=(12, 6))\n",
    "for u_idx, unit_spiketimes in enumerate(alm_insert_thal_stim_unit):\n",
    "    plot_spike_raster_and_histogram(unit_spiketimes['contra_ctrl'], unit_spiketimes['ipsi_ctrl'], \n",
    "                                    axes = (axs.flatten()[u_idx + 3*0], axs.flatten()[u_idx + 3*1]),\n",
    "                                    ax_title='ALM-Thal-ctrl', bin_counts=bin_counts)\n",
    "    plot_spike_raster_and_histogram(unit_spiketimes['contra_stim'], unit_spiketimes['ipsi_stim'], \n",
    "                                    axes = (axs.flatten()[u_idx + 3*2], axs.flatten()[u_idx + 3*3]),\n",
    "                                    ax_title='ALM-Thal-stim', bin_counts=bin_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Chery-picking unit and session...\n",
    "# for idx, sess in enumerate(thal_insert_alm_stim.fetch('KEY')): # pick one session here\n",
    "#     print([idx, len(acquisition.TrialSet.Trial & sess & correct_contra_trial_stim),\n",
    "#            len(acquisition.TrialSet.Trial & sess & correct_ipsi_trial_stim)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 units with ALM insert and Thalamus photostim\n",
    "sess = thal_insert_alm_stim.fetch('KEY')\n",
    "thal_insert_alm_stim_unit = [make_unit_spiketimes(unit=unit_no, sess=sess[session_no])\n",
    "                             for unit_no, session_no in zip((1, 1, 1), (1, 2, 35))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spike raster and histogram\n",
    "bin_counts = 200\n",
    "fig3, axs = plt.subplots(4, len(alm_insert_thal_stim_unit), figsize=(12, 6))\n",
    "for u_idx, unit_spiketimes in enumerate(thal_insert_alm_stim_unit):\n",
    "    plot_spike_raster_and_histogram(unit_spiketimes['contra_ctrl'], unit_spiketimes['ipsi_ctrl'], \n",
    "                                    axes = (axs.flatten()[u_idx + 3*0], axs.flatten()[u_idx + 3*1]),\n",
    "                                    ax_title='ALM-Thal-ctrl', bin_counts=bin_counts)\n",
    "    plot_spike_raster_and_histogram(unit_spiketimes['contra_stim'], unit_spiketimes['ipsi_stim'], \n",
    "                                    axes = (axs.flatten()[u_idx + 3*2], axs.flatten()[u_idx + 3*3]),\n",
    "                                    ax_title='ALM-Thal-stim', bin_counts=bin_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population - Fig 3e and 6e\n",
    "Similarly, for the entire population, instead of picking a few representative units for plotting, here we will query all units from all sessions constrained by the recording/stimulation brain regions and trial-condition restrictors defined above.\n",
    "\n",
    "The routines for plotting the spike histogram is analogous to that above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get trial-segmented spiketimes for all units in all specifed sessions\n",
    "def extract_segmented_spiketimes_histogram(sess_key, trial_key, seg_param_key, time_range=(-1.5, 3), bin_counts=100):\n",
    "    unit_trial_keys = (analysis.TrialSegmentedUnitSpikeTimes & sess_key & seg_param_key &\n",
    "                 (acquisition.TrialSet.Trial & trial_key)).fetch('KEY')\n",
    "    print(f'Found {len(unit_trial_keys)} total trials')\n",
    "        \n",
    "    def make_spike_histogram():\n",
    "        for idx, k in enumerate(unit_trial_keys):\n",
    "            segmented_spike_times = (analysis.TrialSegmentedUnitSpikeTimes & k).fetch1('segmented_spike_times')\n",
    "            if segmented_spike_times.size > 0:\n",
    "                segmented_spike_times = segmented_spike_times[np.logical_and(segmented_spike_times >= time_range[0] \n",
    "                                                              , segmented_spike_times <= time_range[-1])]\n",
    "                spk_counts, spk_edges = np.histogram(segmented_spike_times, bins=bin_counts, range=time_range)\n",
    "                yield spk_counts / np.diff(spk_edges), spk_edges[1:]\n",
    "            \n",
    "    return {'data': np.vstack(x[0] for x in make_spike_histogram()), 'timestamps': next(make_spike_histogram())[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get segmented spike times for population - ALM/thal-insert, thal-stim\n",
    "stim_trial =  {'trial_is_good': True, 'trial_stim_present': True}\n",
    "ctrl_trial =  {'trial_is_good': True, 'trial_stim_present': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_spikes = {name_k: {'ctrl': extract_segmented_spiketimes_histogram(sess_k, ctrl_trial, seg_param_key,\n",
    "                                                                   (-0.2, 0.5), 200),\n",
    "                              'stim': extract_segmented_spiketimes_histogram(sess_k, stim_trial, seg_param_key,\n",
    "                                                                   (-0.2, 0.5), 200)}\n",
    "                     for name_k, sess_k in zip(('alm_insert_thal_stim', 'thal_insert_thal_stim', \n",
    "                                                'alm_insert_alm_stim', 'thal_insert_alm_stim'),\n",
    "                                               (alm_insert_thal_stim, thal_insert_thal_stim, \n",
    "                                                alm_insert_alm_stim, thal_insert_alm_stim))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig36, axs = plt.subplots(2, 2, figsize=(6, 6))\n",
    "fig36.subplots_adjust(hspace=0.3)\n",
    "for s, ax in zip(population_spikes.keys(), axs.flatten()):\n",
    "    plot_with_sem(population_spikes[s]['stim'], population_spikes[s]['ctrl'], ax)\n",
    "    ax.set_xlim(-0.02, 0.04);\n",
    "    ax.set_title(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
